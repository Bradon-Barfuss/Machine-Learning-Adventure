{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7e54c6d",
      "metadata": {
        "id": "f7e54c6d"
      },
      "source": [
        "# CS-6600 Assignment #4 - Binary Classification\n",
        "\n",
        "**YOUR NAME HERE**\n",
        "\n",
        "*Weber State University*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71e8288",
      "metadata": {
        "id": "f71e8288"
      },
      "source": [
        "This assignment is a bit of a right of passage in the machine learning community. It's a binary classification problem based upon a famous historic event - [the sinking of the Titanic](https://en.wikipedia.org/wiki/Titanic).\n",
        "\n",
        "For reference, the RMS Titanic was a British passenger liner which sank in the North Atlantic Ocean on April 15th, 1912 after striking an iceberg during its maiden voyage from Southampton, England to New York City, United States. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, making it the deadliest sinking of a single ship up to that time, and it remains the deadliest sinking of an ocean liner or cruise ship.\n",
        "\n",
        "It was also notable because there were quite a few hours between when the ship struck the iceberg and when it went under, and most of those who survived did so by boarding lifeboats. In other words, there was a (noisy and nonuniform) process that determined who would be on the lifeboats and who would not, and this process mostly determined who survived.\n",
        "\n",
        "For this assignment, we're going to try to predict who survives based upon known passenger information.\n",
        "\n",
        "*Note* - Whether a passenger was on a floating door isn't one of the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25646506",
      "metadata": {
        "id": "25646506"
      },
      "source": [
        "<center>\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1Tb7l6nDAQog3imqv24znRQiMcUkm_dUY\" alt=\"Titanic Door\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c41e48",
      "metadata": {
        "id": "97c41e48"
      },
      "source": [
        "The variables we will have are:\n",
        "\n",
        "|*Variable* |*Description* |*Details* |\n",
        "|:----|:----|:----|\n",
        "|survival|Whether the passenger survived|0 = No, 1 = Yes|\n",
        "|pclass|The passenger class of the ticket|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
        "|name| First and last name of the passenger||\n",
        "|sex|The gender of the passenger||\n",
        "|age|The age of the passenger||\n",
        "|sibsp|The number of siblings / spouses on the ship with the passenger||\n",
        "|parch|The number of parents / children on the ship with the passenger||\n",
        "|ticket|The ticket number||\n",
        "|fare|The cost of the ticket||\n",
        "|embarked|The port of embarcation for the passenger|C = Cherbourg, Q = Queenstown, S = Southampton|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abdbe859",
      "metadata": {
        "id": "abdbe859"
      },
      "source": [
        "Note that we're using a slightly modified and cleaned version of the commonly available Titanic dataset. Before we import the data, we'll first import our favorite libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd11543a",
      "metadata": {
        "id": "fd11543a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then, we'll grab some more."
      ],
      "metadata": {
        "id": "w1eId-UOGB7S"
      },
      "id": "w1eId-UOGB7S"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns #Data visualization library based on matplotlib\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from graphviz import Source\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "PvcHqYy_GHBb"
      },
      "id": "PvcHqYy_GHBb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's get the dataset. The code below should let you import if from my (Dylan's) Google Drive."
      ],
      "metadata": {
        "id": "dRSHGnrZGPo9"
      },
      "id": "dRSHGnrZGPo9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07786f5e",
      "metadata": {
        "id": "07786f5e"
      },
      "outputs": [],
      "source": [
        "#Import the Titanic data\n",
        "url = 'https://drive.google.com/uc?export=download&id=1Oytm0kGCmWsydZrRvCyK_cOE2WfnaVIA'\n",
        "titanic_col_names = ['PassengerID','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Embarked']\n",
        "titanic = pd.read_csv(url,header=0,names=titanic_col_names)\n",
        "titanic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "165cfd21",
      "metadata": {
        "id": "165cfd21"
      },
      "source": [
        "I'll also import the seaborn data visualization library based on matplotlib, set a couple style parameters, and get rid of some annoying warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edcc5172",
      "metadata": {
        "id": "edcc5172"
      },
      "outputs": [],
      "source": [
        "#import seaborn as sns #Data visualization library based on matplotlib\n",
        "\n",
        "#Set some style parameters for seaborn\n",
        "#sns.set(style=\"white\") #white background style for seaborn plots\n",
        "#sns.set(style=\"whitegrid\", color_codes=True)\n",
        "#Get rid of some annying warnings\n",
        "#import warnings\n",
        "#warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deb4b8e0",
      "metadata": {
        "id": "deb4b8e0"
      },
      "source": [
        "Have you heard the phrase \"women and children first?\" Well, it relates to the [code of conduct](https://en.wikipedia.org/wiki/Women_and_children_first) that is supposed to be practiced in a life-threatening situation. Let's see if it's a decent predictor on the Titanic. In particulary, let's look at how survival percentage broke down by gender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80070e73",
      "metadata": {
        "id": "80070e73"
      },
      "outputs": [],
      "source": [
        "#Examine survival by gender\n",
        "sns.barplot(x='Sex',y='Survived', data=titanic)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c394bfc4",
      "metadata": {
        "id": "c394bfc4"
      },
      "source": [
        "Whoa! Looks like many more men went down with the ship. Now, let's take a look at survival rates based on age, and see how well the \"children\" aspect of that dictum holds up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c32bee",
      "metadata": {
        "id": "d4c32bee"
      },
      "outputs": [],
      "source": [
        "#Survival by age histogram\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.histplot(titanic[\"Age\"][titanic.Survived == 1], label='Survived', color='blue', bins=17, kde=False)\n",
        "sns.histplot(titanic[\"Age\"][titanic.Survived == 0], label='Died', color='red', bins=17, kde=False)\n",
        "plt.legend(['Survived', 'Died'])\n",
        "plt.title('Histogram of Age for Surviving Population and Deceased Population')\n",
        "plt.xlabel('Age')\n",
        "plt.xlim(0,85)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2863119",
      "metadata": {
        "id": "d2863119"
      },
      "source": [
        "OK, it looks like being a child did make one more likely to survive as well.\n",
        "\n",
        "Let's use these two characteristics - age and gender - to build a decision tree predictive model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ed9c0f",
      "metadata": {
        "id": "31ed9c0f"
      },
      "source": [
        "First, we're going to want to convert our gender data column into a numeric one. So, we'll create a dummy \"male\" variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c194b973",
      "metadata": {
        "id": "c194b973"
      },
      "outputs": [],
      "source": [
        "#Create a dummy \"male\" variable\n",
        "#WARNING - If you run this twice, you'll create two distinct dummy variable columns\n",
        "gender = pd.get_dummies(titanic[\"Sex\"],drop_first=True)\n",
        "titanic = pd.concat([titanic,gender], axis='columns')\n",
        "titanic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ad92def",
      "metadata": {
        "id": "7ad92def"
      },
      "source": [
        "Then we'll create a dependent and independent variable for the logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf069732",
      "metadata": {
        "id": "cf069732"
      },
      "outputs": [],
      "source": [
        "#Create the dependent and independent variable for the logistic model\n",
        "X = titanic[[\"Age\",\"male\"]]\n",
        "y = titanic[\"Survived\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c291ef",
      "metadata": {
        "id": "d5c291ef"
      },
      "source": [
        "We'll split our data into a training dataset and a test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7edec8a",
      "metadata": {
        "id": "f7edec8a"
      },
      "outputs": [],
      "source": [
        "#Split the data into training data and test data, 75/25\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .25,random_state = 1912)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5c1d2df",
      "metadata": {
        "id": "f5c1d2df"
      },
      "source": [
        "Then, we'll build our decision tree predictive model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e904b4e",
      "metadata": {
        "id": "2e904b4e"
      },
      "outputs": [],
      "source": [
        "#Build the logistic model using the Fare variable\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "tree_clf.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can graph visualize this decision tree with the code below."
      ],
      "metadata": {
        "id": "aKihZGQzHomX"
      },
      "id": "aKihZGQzHomX"
    },
    {
      "cell_type": "code",
      "source": [
        "export_graphviz(\n",
        "        tree_clf,\n",
        "        out_file=str(\"titanic_decision_tree.dot\"),\n",
        "        feature_names=[\"Age\", \"Gender\"],\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )\n",
        "Source.from_file(\"titanic_decision_tree.dot\")"
      ],
      "metadata": {
        "id": "xXsyc3xF-IeL"
      },
      "id": "xXsyc3xF-IeL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "583e0577",
      "metadata": {
        "id": "583e0577"
      },
      "source": [
        "It looks like it first splits on gender, and then on age, but the age split is very different for the men and women."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll use this model to predict survival in the test dataset."
      ],
      "metadata": {
        "id": "E3jCuSCEH2df"
      },
      "id": "E3jCuSCEH2df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8bd2ba3",
      "metadata": {
        "id": "d8bd2ba3"
      },
      "outputs": [],
      "source": [
        "#Use the model to predict the y values in the test set.\n",
        "y_pred = tree_clf.predict(X_test[[\"Age\",\"male\"]])\n",
        "#Create the confusion matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a589505b",
      "metadata": {
        "id": "a589505b"
      },
      "source": [
        "We can check our accuracy, precision, and recall:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0ecdfe",
      "metadata": {
        "id": "bb0ecdfe"
      },
      "outputs": [],
      "source": [
        "#Check the accuracy, precision, and recall\n",
        "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
        "print(\"Precision:\",precision_score(y_test,y_pred))\n",
        "print(\"Recall:\",recall_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed142797",
      "metadata": {
        "id": "ed142797"
      },
      "source": [
        "Grab the probabilities for the ROC curve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cba12f3",
      "metadata": {
        "id": "6cba12f3"
      },
      "outputs": [],
      "source": [
        "#Get the probabilities for the ROC curve\n",
        "pred_prob = tree_clf.predict_proba(X_test[[\"Age\",\"male\"]])\n",
        "fpr, tpr, thresh = roc_curve(y_test, pred_prob[:,1],pos_label=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f077da1c",
      "metadata": {
        "id": "f077da1c"
      },
      "source": [
        "Finally, graph the ROC curve and get the AUC score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc89df53",
      "metadata": {
        "id": "bc89df53"
      },
      "outputs": [],
      "source": [
        "#Graph the ROC curve and display the AUC score\n",
        "plt.plot(fpr,tpr)\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "roc_auc_score(y_test,pred_prob[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df938a2",
      "metadata": {
        "id": "2df938a2"
      },
      "source": [
        "An AUC of .81 isn't great, but it's not terrible. For this assignment, you're going to see if you can do better.\n",
        "\n",
        "The rules are:\n",
        "\n",
        "- You need to use a logistic regression model.\n",
        "- You can only use tha data provided in the dataset, and obviously you can't use \"survival\" (the variable you want to predict) as a predictor.\n",
        "- You should build your model on the training data produced above, and test it (ROC curve and AUC score) on the test data produced above.\n",
        "\n",
        "Do some data exploration, try to figure out a good model, and prove the ROC curve and AUC score for the one you find. Please chart the ROC curve and provide the AUC score as above. Full credit will be awarded if you can find an AUC above .8, and a bonus will go to whoever in the class can produce the best model as measured by AUC score on the test dataset.\n",
        "\n",
        "*Hint* - It helps to be rich."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assignment is this - do some data exploration and try to figure out a good model. Use random forest as your predictor, and do some data exploration to figure out which variables you want to use, and why.\n",
        "\n",
        "Once you've got a good model, please chart the ROC curve and provide the AUC score as above.\n",
        "\n",
        "I'll run your model on a test dataset, with extra credit and glory to whoever gets the highest AUC."
      ],
      "metadata": {
        "id": "2YusQ5a-IFXw"
      },
      "id": "2YusQ5a-IFXw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes\n",
        "\n",
        "*  [The Titanic competition on Kaggle](https://www.kaggle.com/competitions/titanic).\n",
        "*  [Soundtrack](https://www.youtube.com/watch?v=9bFHsd3o1w0) (Could there by any other option?)\n",
        "\n"
      ],
      "metadata": {
        "id": "sOx7Yt85IvFt"
      },
      "id": "sOx7Yt85IvFt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ed7988",
      "metadata": {
        "id": "88ed7988"
      },
      "outputs": [],
      "source": [
        "#Your work here."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "anaconda-2022.05-py39",
      "language": "python",
      "name": "conda-env-anaconda-2022.05-py39-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}